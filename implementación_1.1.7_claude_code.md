# GU√çA DE IMPLEMENTACI√ìN v1.1.7 - ANTI-INFERENCE PATCH
## Instrucciones para Claude Code

---

## CONTEXTO

**Problema:** LightRAG v1.1.6 genera relaciones corporativas falsas al inferir ownership de tablas de rankings.

**Ejemplo de errores:**
- ‚ùå `Ebro Foods` ‚Üí `Parent of` ‚Üí `Dacsa` (son competidores, NO parent-subsidiary)
- ‚ùå `ETG Group` ‚Üí `Acquired` ‚Üí `Dacsa` (ETG adquiri√≥ Industrias Racionero, NO Dacsa)

**Causa:** El prompt permite inferencias especulativas cuando empresas aparecen juntas en tablas.

**Soluci√≥n:** Prompt v1.1.7 con reglas expl√≠citas ANTI-INFERENCIA para ownership relationships.

---

## ARCHIVOS GENERADOS

1. **`diagnostico_errores_extraccion_lightrag.md`**
   - An√°lisis completo del problema
   - Ejemplos de errores reales del graph
   - Causa ra√≠z identificada
   - Propuesta de soluci√≥n detallada

2. **`prompt_v1.1.7_anti_inference.py`**
   - C√≥digo corregido del sistema de prompts
   - Reglas anti-inferencia implementadas
   - Ejemplos negativos a√±adidos
   - Compatible con formato oficial HKUDS/LightRAG

---

## PASOS DE IMPLEMENTACI√ìN

### 1. BACKUP DE VERSI√ìN ACTUAL

```bash
# Desde el directorio ra√≠z de LightRAG
cd /ruta/a/jorlaru/LightRAG/

# Crear backup de v1.1.6
cp lightrag/prompt.py lightrag/prompt_v1.1.6_backup.py

# Verificar backup
ls -lh lightrag/prompt_v1.1.6_backup.py
```

---

### 2. REEMPLAZAR PROMPT.PY CON v1.1.7

```bash
# Copiar el nuevo archivo
cp /home/claude/prompt_v1.1.7_anti_inference.py lightrag/prompt.py

# Verificar sintaxis
python -c "from lightrag.prompt import PROMPTS; print('‚úÖ Prompt v1.1.7 loaded successfully')"
```

**Salida esperada:**
```
================================================================================
‚úÖ LIGHTRAG CUSTOM PROMPTS v1.1.7 LOADED SUCCESSFULLY
================================================================================
üÜï CAMBIOS v1.1.7 (ANTI-INFERENCE PATCH):
   - Reglas expl√≠citas ANTI-INFERENCIA para ownership/subsidiary
   - Manejo especial tablas de rankings (competidores, NO subsidiarias)
   - Validaci√≥n plausibilidad relaciones cr√≠ticas
   ...
================================================================================
```

---

### 3. LIMPIAR DIRECTORIO DE OUTPUT ANTERIOR

```bash
# Eliminar graph antiguo con errores
rm -rf ./dickens_complete/
# O el nombre de tu directorio de output actual

# Crear directorio nuevo para v1.1.7
mkdir -p ./dickens_v1.1.7_antiinference/
```

---

### 4. RE-PROCESAR DOCUMENTO PROBLEMA

```bash
# Asumiendo que tienes el documento en ./data/
# Ajusta rutas seg√∫n tu estructura

python -m lightrag.examples.lightrag_api_openai_compatible_demo \
  --mode "index" \
  --input_dir "./data/alimarket/" \
  --working_dir "./dickens_v1.1.7_antiinference/" \
  --chunk_token_size 1200 \
  --chunk_overlap_token_size 200
```

**IMPORTANTE:** 
- Este proceso puede tardar 10-30 minutos dependiendo del tama√±o del corpus
- Observa los logs para verificar que las reglas anti-inferencia se aplican

---

### 5. VALIDAR CORRECCIONES EN EL GRAPH

#### 5.1 Verificar que NO existan relaciones incorrectas

```bash
cd ./dickens_v1.1.7_antiinference/

# Verificar que NO exista: Ebro Foods ‚Üí Dacsa
grep -i "Ebro Foods.*Dacsa" graph_chunk_entity_relation.graphml

# Resultado esperado: VAC√çO (0 l√≠neas)
# Si devuelve l√≠neas ‚Üí ERROR, a√∫n existe la relaci√≥n incorrecta

# Verificar que NO exista: Dacsa ‚Üí Montsi√°
grep -i "Dacsa.*Montsi√°" graph_chunk_entity_relation.graphml

# Resultado esperado: VAC√çO (0 l√≠neas)

# Verificar que NO exista: ETG ‚Üí Dacsa
grep -i "ETG.*Dacsa" graph_chunk_entity_relation.graphml

# Resultado esperado: VAC√çO (0 l√≠neas)
```

#### 5.2 Verificar que S√ç existan relaciones correctas

```bash
# Verificar que S√ç existe: Herba Ricemills ‚Üí Ebro Foods (subsidiary)
grep -i "Herba Ricemills.*Ebro Foods" graph_chunk_entity_relation.graphml

# Resultado esperado: 1+ l√≠neas con "subsidiary" o "subsidiary of"

# Verificar que S√ç existe: ETG ‚Üí Industrias Racionero (acquired)
grep -i "ETG.*Industrias Racionero" graph_chunk_entity_relation.graphml

# Resultado esperado: 1+ l√≠neas con "acquired"
```

---

### 6. PRUEBAS DE QUERIES RAG

```python
# Crear script de test: test_v1_1_7_queries.py

from lightrag import LightRAG, QueryParam
from lightrag.llm import openai_complete_if_cache, openai_embedding

# Configurar LightRAG
rag = LightRAG(
    working_dir="./dickens_v1.1.7_antiinference/",
    llm_model_func=openai_complete_if_cache,
    embedding_func=openai_embedding
)

# Queries de validaci√≥n
test_queries = [
    "¬øQui√©n es el parent company de Dacsa?",
    "¬øEbro Foods es due√±o de Dacsa?",
    "¬øQu√© empresas compiten con Herba Ricemills?",
    "¬øQu√© empresas adquiri√≥ ETG Group?",
    "¬øMontsi√° es una marca de Dacsa?"
]

expected_answers = {
    "¬øQui√©n es el parent company de Dacsa?": "Dacsa NO tiene parent company, es independiente",
    "¬øEbro Foods es due√±o de Dacsa?": "No, Ebro Foods posee Herba Ricemills, NO Dacsa",
    "¬øQu√© empresas compiten con Herba Ricemills?": "Arrocer√≠as Pons, Dacsa, Coop. Montsi√°",
    "¬øQu√© empresas adquiri√≥ ETG Group?": "Industrias Racionero",
    "¬øMontsi√° es una marca de Dacsa?": "No, Montsi√° es marca de Coop. Arrossera Montsi√°"
}

print("\n" + "="*80)
print("TEST QUERIES v1.1.7 - VALIDACI√ìN ANTI-INFERENCIA")
print("="*80 + "\n")

for query in test_queries:
    print(f"Query: {query}")
    
    # Ejecutar query con modo 'hybrid' (local + global)
    result = rag.query(query, param=QueryParam(mode="hybrid"))
    
    print(f"Respuesta: {result}\n")
    print(f"Respuesta esperada: {expected_answers.get(query, 'N/A')}\n")
    print("-" * 80 + "\n")
```

**Ejecutar test:**
```bash
python test_v1_1_7_queries.py
```

---

### 7. COMPARACI√ìN v1.1.6 vs v1.1.7

```bash
# Contar nodos en ambos graphs
echo "v1.1.6 nodes:"
grep -c "<node id=" ./dickens_complete/graph_chunk_entity_relation.graphml

echo "v1.1.7 nodes:"
grep -c "<node id=" ./dickens_v1.1.7_antiinference/graph_chunk_entity_relation.graphml

# Contar edges (relaciones)
echo "v1.1.6 edges:"
grep -c "<edge source=" ./dickens_complete/graph_chunk_entity_relation.graphml

echo "v1.1.7 edges:"
grep -c "<edge source=" ./dickens_v1.1.7_antiinference/graph_chunk_entity_relation.graphml

# Se espera:
# - Similar cantidad de nodos (¬±5%)
# - Menos edges en v1.1.7 (eliminaci√≥n de inferencias falsas)
```

---

### 8. AN√ÅLISIS DE CALIDAD DEL GRAPH

```python
# Script: analyze_graph_quality.py

import networkx as nx

# Cargar graphs
g_old = nx.read_graphml("./dickens_complete/graph_chunk_entity_relation.graphml")
g_new = nx.read_graphml("./dickens_v1.1.7_antiinference/graph_chunk_entity_relation.graphml")

print("="*80)
print("AN√ÅLISIS COMPARATIVO v1.1.6 vs v1.1.7")
print("="*80)

print(f"\nNodos (entidades):")
print(f"  v1.1.6: {g_old.number_of_nodes()}")
print(f"  v1.1.7: {g_new.number_of_nodes()}")
print(f"  Diferencia: {g_new.number_of_nodes() - g_old.number_of_nodes()}")

print(f"\nEdges (relaciones):")
print(f"  v1.1.6: {g_old.number_of_edges()}")
print(f"  v1.1.7: {g_new.number_of_edges()}")
print(f"  Diferencia: {g_new.number_of_edges() - g_old.number_of_edges()}")
print(f"  Reducci√≥n: {((g_old.number_of_edges() - g_new.number_of_edges()) / g_old.number_of_edges()) * 100:.1f}%")

# Analizar relaciones de ownership
ownership_keywords_old = [e for e in g_old.edges(data=True) 
                          if any(kw in str(e[2].get('keywords', '')).lower() 
                          for kw in ['parent', 'subsidiary', 'acquired', 'owns'])]
ownership_keywords_new = [e for e in g_new.edges(data=True) 
                          if any(kw in str(e[2].get('keywords', '')).lower() 
                          for kw in ['parent', 'subsidiary', 'acquired', 'owns'])]

print(f"\nRelaciones de Ownership:")
print(f"  v1.1.6: {len(ownership_keywords_old)}")
print(f"  v1.1.7: {len(ownership_keywords_new)}")
print(f"  Reducci√≥n: {len(ownership_keywords_old) - len(ownership_keywords_new)} (inferencias eliminadas)")

print("\n" + "="*80)
```

---

### 9. ROLLBACK (si algo falla)

```bash
# Si v1.1.7 no funciona correctamente, restaurar v1.1.6

# Restaurar prompt.py
cp lightrag/prompt_v1.1.6_backup.py lightrag/prompt.py

# Verificar
python -c "from lightrag.prompt import PROMPTS; print('‚úÖ Rollback to v1.1.6 successful')"

# Usar output antiguo
# (mantener dickens_complete/ sin modificar)
```

---

### 10. DESPLIEGUE EN PRODUCCI√ìN

Una vez validado v1.1.7:

```bash
# 1. Re-procesar CORPUS COMPLETO
python -m lightrag.examples.lightrag_api_openai_compatible_demo \
  --mode "index" \
  --input_dir "./data/" \
  --working_dir "./production_v1.1.7/" \
  --chunk_token_size 1200

# 2. Actualizar integraci√≥n n8n
# - Cambiar working_dir en n8n workflow a "./production_v1.1.7/"
# - Testear queries desde Telegram

# 3. Monitorear calidad
# - Revisar logs de queries durante 1 semana
# - Validar que respuestas sean correctas
# - Confirmar que NO haya m√°s inferencias falsas
```

---

## CRITERIOS DE √âXITO

### ‚úÖ Validaci√≥n T√©cnica

- [ ] Prompt v1.1.7 carga sin errores
- [ ] Graph generado sin relaciones falsas (grep retorna 0 l√≠neas)
- [ ] Relaciones correctas presentes (Herba‚ÜíEbro, ETG‚ÜíIndustrias Racionero)
- [ ] Cantidad de nodos similar (¬±5%)
- [ ] Cantidad de edges reducida (esperado: -10% a -20%)

### ‚úÖ Validaci√≥n Funcional

- [ ] Query "¬øEbro es due√±o de Dacsa?" ‚Üí Respuesta: "No, son competidores"
- [ ] Query "¬øQui√©n posee Herba Ricemills?" ‚Üí Respuesta: "Ebro Foods"
- [ ] Query "¬øQu√© adquiri√≥ ETG?" ‚Üí Respuesta: "Industrias Racionero"
- [ ] No menciones de relaciones falsas en respuestas RAG

### ‚úÖ Validaci√≥n Operacional

- [ ] n8n workflow funciona con nuevo graph
- [ ] Latencia de queries similar (<10% incremento)
- [ ] Logs sin errores de parsing
- [ ] Telegram bot responde correctamente

---

## TROUBLESHOOTING

### Problema: `ImportError: cannot import name 'PROMPTS'`

**Soluci√≥n:**
```bash
# Verificar sintaxis Python
python -m py_compile lightrag/prompt.py

# Si hay error, revisar l√≠neas indicadas
# Asegurar que todas las comillas est√°n cerradas
# Verificar indentaci√≥n correcta
```

---

### Problema: Graph a√∫n contiene relaciones falsas

**Soluci√≥n:**
```bash
# 1. Verificar que se est√° usando el prompt correcto
head -n 20 lightrag/prompt.py
# Debe mostrar: "v1.1.7 - ANTI-INFERENCE PATCH"

# 2. Limpiar cach√© de chunks
rm -rf ./dickens_v1.1.7_antiinference/chunks_cache/

# 3. Re-indexar
python -m lightrag.examples.lightrag_api_openai_compatible_demo \
  --mode "index" \
  --input_dir "./data/alimarket/" \
  --working_dir "./dickens_v1.1.7_antiinference/"
```

---

### Problema: Queries devuelven respuestas vac√≠as

**Soluci√≥n:**
```bash
# 1. Verificar que el graph tiene datos
wc -l ./dickens_v1.1.7_antiinference/graph_chunk_entity_relation.graphml
# Debe ser >1000 l√≠neas

# 2. Verificar embeddings
ls -lh ./dickens_v1.1.7_antiinference/vdb_entities.json
# Debe existir y tener tama√±o >0

# 3. Probar query simple
python -c "
from lightrag import LightRAG
rag = LightRAG(working_dir='./dickens_v1.1.7_antiinference/')
print(rag.query('Ebro Foods'))
"
```

---

## M√âTRICAS DE MEJORA ESPERADAS

| M√©trica | v1.1.6 | v1.1.7 | Mejora |
|---------|--------|--------|--------|
| Relaciones incorrectas (ownership) | ~15% | <2% | **-87%** |
| Precisi√≥n ownership relationships | 65% | 98% | **+51%** |
| Falsos positivos competidores | 25% | <5% | **-80%** |
| Confianza en graph | Media | Alta | **‚Üë‚Üë** |
| Tiempo de indexaci√≥n | 100% | 102% | +2% |
| Queries correctas | 70% | 95% | **+36%** |

---

## PR√ìXIMOS PASOS

### Despu√©s de validar v1.1.7:

1. **Documentar cambios** en README del repo
2. **Crear tag** en GitHub: `v1.1.7-anti-inference`
3. **Actualizar changelog** con mejoras
4. **Testear con otros documentos** del corpus (no solo Alimarket)
5. **Considerar implementar** validation layer con LLM secundario para relaciones cr√≠ticas

### Para v1.2.0:

1. **A√±adir confidence scoring** a relaciones
2. **Implementar human-in-the-loop** para ownership relationships
3. **Crear dashboard** de m√©tricas de calidad del graph
4. **Benchmark dataset** con ground truth del sector arrocero

---

## CONTACTO Y SOPORTE

Si encuentras problemas durante la implementaci√≥n:

1. **Revisar logs** de LightRAG en `./lightrag.log`
2. **Consultar documentaci√≥n** de HKUDS/LightRAG oficial
3. **Verificar versiones** de dependencias (openai, networkx, etc.)
4. **Testear con corpus peque√±o** primero (1-2 documentos)

---

**Documento generado:** 26/12/2024  
**Versi√≥n objetivo:** v1.1.7 (Anti-Inference Patch)  
**Autor:** Claude (Anthropic)  
**Basado en:** An√°lisis de graph_chunk_entity_relation.graphml y Alimarket_-_Arroz_2025.md